import streamlit as st
from transformers import pipeline
import os

# Hugging Face API anahtarÄ±nÄ± buraya girin
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_senin_token_kodun"

st.set_page_config(page_title="MediGuide", page_icon="ğŸ§¬")

st.title("ğŸ©º MediGuide - SaÄŸlÄ±k AsistanÄ± AI")
st.write("ğŸ“Œ SaÄŸlÄ±kla ilgili sorularÄ±nÄ±zÄ± yazÄ±n, yapay zeka yardÄ±mcÄ± olsun.")

@st.cache_resource
def get_model():
    return pipeline("text-generation", model="mistralai/Mistral-7B-Instruct-v0.1", 
                    tokenizer="mistralai/Mistral-7B-Instruct-v0.1", 
                    max_length=256, 
                    temperature=0.7)

qa_pipeline = get_model()

soru = st.text_input("ğŸ§  Sorunuzu yazÄ±n:", placeholder="Ã–rn: BaÅŸ aÄŸrÄ±sÄ±na ne iyi gelir?")

if soru:
    with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
        yanit = qa_pipeline(soru)[0]['generated_text']
        st.success(f"ğŸ’¬ Cevap: {yanit}")